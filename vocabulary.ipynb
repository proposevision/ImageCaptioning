{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "import os.path\n",
    "from pycocotools.coco import COCO\n",
    "from collections import Counter\n",
    "\n",
    "class Vocabulary(object):\n",
    "    def __init__(self, vocab_threshold, vocab_file='./vocab.pkl', start_word=\"<start>\", end_word=\"<end>\", unk_word=\"<unk>\", annotations_file='../cocoapi/annotations/captions_train2014.json',vocab_from_file=False):\n",
    "        self.vocab_threshold = vocab_threshold\n",
    "        self.start_word = start_word\n",
    "        self.end_word = end_word\n",
    "        self.unk_word = unk_word\n",
    "        self.annotations_file = annotations_file\n",
    "        self.vocab_file = vocab_file\n",
    "        self.vocab_from_file = vocab_from_file\n",
    "        self.get_vocab()\n",
    "        \n",
    "    def get_vocab(self):\n",
    "        #load vocab from file or build vocab from scratch\n",
    "        if os.path.exist(self.vocab_file) and self.vocab_from_file:\n",
    "            with open(self.vocab_file, 'rb') as f:\n",
    "                vocab = pickle.load(f)\n",
    "                self.word2idx = vocab.word2idx\n",
    "                self.idx2word = vocab.idx2word\n",
    "                print(\"vocab successfully loaded from vocab.pkl\")\n",
    "        else:\n",
    "            self.build_vocab()\n",
    "            with open(self.vocab_file, 'wb') as f:\n",
    "                pickle.dump(self, f)\n",
    "            \n",
    "    def build_vocab(self):\n",
    "        self.init_vocab()\n",
    "        self.add_word(self.start_word)\n",
    "        self.add_word(self.end_word)\n",
    "        self.add_word(self.unk_word)\n",
    "        self.add_captions()\n",
    "        \n",
    "    def init_vocab(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        # add token to vocab\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "            \n",
    "    def add_captions(self):\n",
    "        #loop over training captions and add all tokens to vocab if it satisfies to threshold\n",
    "        coco = COCO(self.annotations_file)\n",
    "        counter = Counter()\n",
    "        ids = coco.anns.keys()\n",
    "        for i, id in enumerate(ids):\n",
    "            caption = str(coco.anns[id]['caption'])\n",
    "            tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "            counter.update(tokens)\n",
    "            \n",
    "            if i % 100000 == 0:\n",
    "                print(\"[%d/%d] Tokenizing captions..\" % (i, len(ids)))\n",
    "        \n",
    "        words = [word for word, cnt in counter.items() if cnt >= self.vocab_threshold]\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            self.add_word(word)\n",
    "    def __call__(self):\n",
    "        if not word in self.word2idx:\n",
    "            return self.word2idx[self.unk_word]\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4613,  0.7748, -0.9540],\n",
       "         [-1.9958,  0.8001, -0.2460],\n",
       "         [ 1.4827, -0.7581,  0.8209]]),\n",
       " Counter({tensor([ 1.4613,  0.7748, -0.9540]): 1,\n",
       "          tensor([-1.9958,  0.8001, -0.2460]): 1,\n",
       "          tensor([ 1.4827, -0.7581,  0.8209]): 1}))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "asd = torch.randn(3,3)\n",
    "counter = Counter()\n",
    "\n",
    "counter.update(asd)\n",
    "asd, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
